---
title: "EMA Preprocessing Report"
author:
  - name: Walter G. Dyer, wdyer@psu.edu, Penn State University
date: "`r Sys.Date()`"
output: 
  html_document:
      toc: true
      number_sections: false
      toc_float: true
      toc_depth: 2
---

<!-- Javascript code to zoom in and out in the plots. -->
<!-- Code from Radovan Miletić: https://stackoverflow.com/questions/56361986/zoom-function-in-rmarkdown-html-plot -->
<script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
    $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
    $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
    $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
});
</script>


<!--------- INSTRUCTIONS ----------
This template would help you to structure and share your preprocessing. 
It is based on the ESM preprocessing framework described in Revol and al. (under review) 
In addition, it is associated with an R package, the esmtools package (https://package.esmtools.com), 
and a website to provide tutorials and R code for each step: https://preprocess.esmtools.com.
Please, follow the instructions commented and add descriptions above each chunk you create. 
This advanced version of the ESM preprocessing report provides instructions on creating an interactive document 
that mainly use esmtools functions (e.g., buttons) to enhanced user experience. 
Note that the commented instructions are not displayed in the rendered document. 
<!--------------------------------->


<!-- 
Txt() and button() css style:
When importing 'esmtools' packages, it comes with CSS styles for class ('esm-issue', 'esm-inspect', 'esm-mod') used by the txt() and button() functions. 
Customize them with CSS code in the provided style tag. 
Modify fonts, colors, etc., as you like (an example is commented).
In certain cases, you might need to use the '!important' declaration to override the default style definitions.
-->
<style>
.esm-issue{
  /* font-family: Georgia; */
}
</style>

<!-- This first chunk define the global settings-->
```{r, include=FALSE}
# Setup global settings
# knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```

# Overview and data collection procedure

This R Markdown file is based on Revol et al. (2024)'s step-by-step guidelines for preprocessing ESM data: [https://preprocess.esmtools.com](https://preprocess.esmtools.com). It includes code adapted from Steps 1 - 4, tailored to preprocess EMA data for a secondary analysis of EMA data from the DVAL project (https://osf.io/nb9ct/overview?view_only=4f777b3907bb47aab6387aaa4353285c). In Part 2 of the study, participants received semi-random prompts 6 times throughout the day within predeterimined 2-hr intervals for three consecutive days, and were instructed to smoke at their normal rate. In Part 6 of the study, the same sampling scheme continued for 7 more days, during which participants were informed they could receive daily cash bonuses for day-level cigarette abstinence and were asked to biochemically verify abstinence daily. Both EMA datasets will be combined for this study's analyses, and time-invariant variables (e.g., age, cigarette dependence) will be pulled from a baseline dataset. The steps to prepare the data for analysis are described below.   

---
# Load packages

Import the packages:
```{r, message=FALSE, warning=FALSE}

#Data management
library(dplyr)
library(tidyr)
library(data.table)
library(here)
library(readr)   
library(readxl)
library(esmtools) # For button(), txt() functions

# Descriptive statistics
library(skimr)

# Missing values inspection
library(naniar)
library(visdat)

# Plotting
library(ggplot2)

# Character manipulation
library(stringr)
library(janitor)

# Dates and times
library(lubridate)
library(hms)
```

# Step 1: Import data and preliminary preprocessing

This section is dedicated to the first look at the data, the merging of data sources the first basic preprocessing methods (e.g., duplicates, branching items check), and checking the variable consistency when the data has just been imported.

Import the data: 
```{r}
# Define path to EMA Part 2 and Part 6 data
part2_path <- here("data", "DVAL_EMA_Part2_beeped.csv")
part6_path <- here("data", "DVAL_EMA_Part6_beeped.csv")
```


`r txt('esm-inspect','Inspection',"Part 2 EMA raw dataset meta-info:",FALSE)` 
```{r}
dataInfo(file_path = part2_path, 
         read_fun = read.csv,
         idvar = "participant_id", 
         timevar = "init_time")
```
`r txt('esm-inspect','Inspection',"Part 6 EMA raw dataset meta-info:",FALSE)` 
```{r}
dataInfo(file_path = part6_path, 
         read_fun = read.csv,
         idvar = "participant_id", 
         timevar = "init_time")
```
# Import data and prepare for preprocessing steps

The following code prepares the EMA data for Revol et. al.'s preprocessing steps. The data are be subset, how to define missing values is specified, variables are formatted to their respective types (e.g., numeric, character), and formatting issues related to cases where participants opted out of a survey are dealt with. 

`r txt('esm-mod','Modification',"Data are subsetted to include only participants who completed Part 2 (Part 6 EMA is already subsetted to include only-completers of Part 6).")`

`r txt('esm-mod','Modification',"EMA variables relevant to the study are extracted, and missingness is standardized across variables.")`

`r txt(id='esm-issue',title='Issue',text="Instances where participants opted out were reported by the literal text 'opted out' in the raw dataset, making the data incompatible with the command to format the variable as numeric.",FALSE)` 

`r txt('esm-mod','Modification',"In order to maintain these data but in a format compatible with numeric formatting, a variable to track opted out instances is created to check whether further actions to account for these cases must be taken, and cases with the text 'opted out' are replaced with 'NA'.")` 

`r txt(id='esm-issue',title='Issue',text="The variable smoked_since_last_survey gave participants the option to select '6+' which, while useful for other analyses, prevents us from formatting the variable as numeric.",FALSE)`

`r txt('esm-mod','Modification',"The chunk below converts '6+' to 6 for the variable smoked_since_last_survey.")`

`r txt(id='esm-issue',title='Issue',text="Continuous variables must be formatted as numeric.",FALSE)`

`r txt('esm-mod','Modification',"The chunk below formats continuous variables as numeric for later analyses.")`

`r txt(id='esm-issue',title='Issue',text="Time variables must be reformatted.",FALSE)`

`r txt('esm-mod','Modification',"The chunk below formats time variables as POSIXct for later analysis.")`

`r button(text = "Description")` 

```{r}
# Define subset of participants who completed Part2 (3 days of EMA data collection)
subset_ids <- c(
  102, 104, 107, 112, 113, 115, 116, 124, 125, 126, 127, 128, 133, 141, 
  150, 151, 154, 159, 163, 164, 166, 169, 175, 177, 180, 186, 188, 192, 
  195, 196, 197, 198, 199, 202, 206, 209, 210, 213, 214, 216, 218, 221, 
  222, 223, 233, 238, 240, 246, 252, 257, 262, 268, 273, 274, 278, 281, 
  282, 286, 287, 290, 291, 295, 297, 300, 301, 304, 310, 314, 320, 321, 
  329, 332, 340, 341, 342, 344, 346, 349, 351, 356, 362, 363, 369, 370, 
  372, 381, 383, 393, 394, 399, 416, 423, 427, 428, 430
)

# Define EMA variables to extract
ema_vars <- c(
  "mood",
  "smoke",
  "before_survey",
  "unpleasant",
  "prior_mood",
  "smoked_since_last_survey",
  "pleasant",
  "participant_id",
  "session_id",
  "completion_time",
  "init_time"
)

# Function to preprocess EMA data

preprocess_ema <- function(path, subset_vector = NULL) {
  
  df <- read_csv(
    path,
    na = c("-99", "__NA__", "NA", ""),
    col_types = cols(.default = col_character()),
    col_select = all_of(ema_vars)
  )
  
  # Subset participants ONLY if subset_vector provided
  if (!is.null(subset_vector)) {
    df <- df %>%
      filter(as.numeric(participant_id) %in% subset_vector)
  }
  
  df %>%
    
    # Track opted out instances
    mutate(across(
      c(mood, smoke, unpleasant, prior_mood,
        smoked_since_last_survey, pleasant, before_survey),
      ~ ifelse(. == "opted out", 1, 0),
      .names = "{.col}_optout"
    )) %>%
    
    # Replace 'opted out' with NA for numeric conversion
    mutate(across(
      c(mood, smoke, unpleasant, prior_mood,
        smoked_since_last_survey, pleasant, before_survey),
      ~ ifelse(. == "opted out", NA, .)
    )) %>%
    
    # Convert 6+ to 6
    mutate(
      smoked_since_last_survey =
        ifelse(smoked_since_last_survey == "6+", "6",
               smoked_since_last_survey)
    ) %>%
    
    # Convert numeric variables
    mutate(across(
      c(mood, smoke, unpleasant, prior_mood,
        smoked_since_last_survey, pleasant,
        participant_id),
      as.numeric
    ))
}

# Apply preprocessing

# Part 2 (needs subsetting)
part2beeped_clean <- preprocess_ema(
  part2_path,
  subset_vector = subset_ids
)

# Part 6 (already subsetted — no participant filtering needed)
part6beeped_clean <- preprocess_ema(
  part6_path,
  subset_vector = NULL
)

# Combine Part 2 and Part 6 datasets

ema_master <- bind_rows(
  part2beeped_clean %>% mutate(study_part = 2),
  part6beeped_clean %>% mutate(study_part = 6)
)

```


```{r}
ema_master <- ema_master %>%
  mutate(init_time = as.POSIXct(init_time, tz = "UTC"),
         completion_time = as.POSIXct(completion_time, tz = "UTC"))
```

`r txt('esm-inspect','Inspection',"opting out behavior by participant",FALSE)` 

```{r}
#mood
ema_master %>%
  select(
    participant_id,
    mood_optout,
    smoke_optout,
    unpleasant_optout,
    prior_mood_optout,
    smoked_since_last_survey_optout,
    pleasant_optout,
    before_survey_optout
  ) %>%
  pivot_longer(
    cols = -participant_id,
    names_to = "variable",
    values_to = "optout"
  ) %>%
  count(participant_id, variable, optout) %>%
  pivot_wider(
    names_from = optout,
    values_from = n,
    values_fill = 0,
    names_prefix = "n_"
  ) %>%
  arrange(participant_id, variable)
```

Note: Participant #372 opted out of responding to 'mood', 'before_survey' and 'smoke' on one occasion; Participant #427 opted out of responding to 'mood' once. Because these behavioral data are not useful moving forward, these data will be treated as missing. Now that this check is complete, all created '_optout' variables are deleted in the following step.

```{r}
ema_master <- ema_master %>%
  select(-ends_with("_optout"))
```

`r endbutton()` 

The EMA data are now prepared for Revol et. al.'s preprocessing workflow but must be merged with the parent study's baseline dataset for time-invariant variables (e.g., covariates). The below code prepares the baseline data for merge.

`r txt(id='esm-issue',title='Issue',text="Baseline data are raw. Some measures of time-invariant characteristics (e.g., Fagerstrom Test for Cigarette Dependence) need scoring and some variables require renaming/relabeling.",FALSE)` 

`r txt('esm-mod','Modification',"Baseline variables are preprocessed according to survey author guidelines (see parent study online repository for full list of baseline measures) and planned analyses.")`

`r button(text = "Description")` 

```{r}
# Define paths to input data
Apath <- here("data", "QuestionnairesA.xlsx")
Bpath <- here("data", "QuestionnairesB.xlsx")

# Read files into dataframes
A <- read_excel(Apath)
B <- read_excel(Bpath)

# Merge the baseline datasets
baseline <- merge(A, B, by = "participant-id", all = TRUE, suffixes = c(".A", ".B"))

# Clean column names 
baseline <- clean_names(baseline)

# Filter to participants who completed Part 2 EMA
analytic_sample <- c(102, 104, 107, 112, 113, 115, 116, 124, 125, 126, 127, 128, 133, 141, 150, 151, 154, 159, 163, 164, 166, 169, 175, 177, 180, 186, 188,
192, 195, 196, 197, 198, 199, 202, 206, 209, 210, 213, 214, 216, 218, 221, 222, 223, 233, 238, 240, 246, 252, 257, 262, 268, 273, 274, 278, 281, 282, 286, 287, 290, 291, 295, 297, 300, 301, 304, 310, 314, 320, 321, 329, 332, 340, 341, 342, 344, 346, 349, 351, 356, 362, 369, 370, 372, 381, 383, 393, 394, 399, 416, 423, 427, 428, 430)
baseline <- baseline %>% filter(participant_id %in% analytic_sample)

# FTND: Fagerstrom Test for Cigarette Dependence
baseline <- baseline %>%
  rename(cigsperday = ftnd_4) %>%
  mutate(ftnd_4 = case_when(
    cigsperday <= 10 ~ 1,
    cigsperday > 10 & cigsperday <= 20 ~ 2,
    cigsperday > 20 & cigsperday <= 30 ~ 3,
    cigsperday > 30 ~ 4
  )) %>%
  mutate(ftnd_sum = ftnd_1 + ftnd_2 + ftnd_3 + ftnd_4 + ftnd_5 + ftnd_6)

# PANAS: Positive and Negative Affect Schedule 
baseline <- baseline %>%
  mutate(
    panas_pos = q64_pan_1 + q64_pan_3 + q64_pan_5 + q64_pan_9 + q64_pan_10 + q64_pan_12 + q64_pan_14 + q64_pan_16 + q64_pan_17 + q64_pan_19,
    panas_neg = q64_pan_2 + q64_pan_4 + q64_pan_6 + q64_pan_7 + q64_pan_8 + q64_pan_11 + q64_pan_13 + q64_pan_15 + q64_pan_18 + q64_pan_20
  )

# SHAPS: Snaith-Hamilton Pleasure Scale 
baseline <- baseline %>%
  mutate(across(starts_with("q14_sha_"), ~ ifelse(. %in% c(1,2), 1, 0), .names = "{.col}_sim")) %>%
  mutate(shaps_sim_sum = q14_sha_1_sim + q14_sha_2_sim + q14_sha_3_sim + q14_sha_4_sim + q14_sha_5_sim + q14_sha_6_sim + 
           q14_sha_7_sim + q14_sha_8_sim + q14_sha_9_sim + q14_sha_10_sim + q14_sha_11_sim + q14_sha_12_sim + 
           q14_sha_13_sim + q14_sha_14_sim)

# Reformat column types 
change_column_types <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    if (is.numeric(col_data) || inherits(col_data, "POSIXct")) next
    if (is.character(col_data)) {
      trimmed <- trimws(col_data)
      numeric_check <- suppressWarnings(!is.na(as.numeric(trimmed)))
      if (all(numeric_check | is.na(trimmed))) {
        df[[col_name]] <- as.integer(trimmed)
      } else {
        df[[col_name]] <- trimmed
      }
    }
  }
  # Convert date columns
  for (col_name in colnames(df)) {
    if (grepl("_date_", col_name)) {
      df[[col_name]] <- as.POSIXct(df[[col_name]], format = "%m/%d/%Y")
    }
  }
  return(df)
}
baseline <- change_column_types(baseline)

# Fix column name typo 
baseline <- baseline %>% rename(total_household_income = total_houselhold_income)

# Subset to analysis-relevant variables 
baseline_clean <- baseline %>%
  select(
    participant_id,
    race,
    age,
    gender,
    total_household_income,
    bank_balance,
    ftnd_sum,
    cigsperday,
    shaps_sim_sum,
    panas_pos,
    panas_neg
  )
```

`r endbutton()` 

Baseline data are now prepared for merging with the EMA data.

`r txt(id='esm-issue',title='Issue',text=" The EMA data alone do not contain all participant data needed for analyses. They must be combined with baseline data.",FALSE)`
`r txt('esm-mod','Modification',"The EMA and Baseline Data are merged in the order: EMA variables, then Baseline variables.")`

`r button(text = "Description")` 

```{r}
# Specify baseline variables
baseline_vars <- c(
  "race",
  "age",
  "gender",
  "total_household_income",
  "bank_balance",
  "ftnd_sum",
  "cigsperday",
  "shaps_sim_sum",
  "panas_pos",
  "panas_neg"
)

# Merge and reorder in a single step
study_sample <- ema_master %>%
  left_join(baseline_clean, by = "participant_id") %>%
  select(
    # All columns except the baseline variables first
    -all_of(baseline_vars),
    # Then baseline variables at the end
    all_of(baseline_vars)
  )
```

`r endbutton()` 

# Flag (in)valid observations

We use logical tests to define which observations are valid so that we can compare the total N of valid observations between the two datasets. The 'valid' observations are the ones where there are no missing values in the variables of interest (i.e., 'mood', 'before_survey', 'smoke'), and two others that branch off of the variable 'before_survey' ('pleasant', 'unpleasant') . Below we create a validity function that can be used to filter data later.
```{r}
# Create validity function 
check_validity <- function(df) {
  
  mood_ok          <- !is.na(df$mood)
  before_survey_ok <- !is.na(df$before_survey)
  smoke_ok         <- !is.na(df$smoke)
  
  # At least one of pleasant or unpleasant must be non-missing
  branch_ok <- !is.na(df$pleasant) | !is.na(df$unpleasant)
  
  is_valid <- mood_ok & before_survey_ok & smoke_ok & branch_ok
  
  as.integer(is_valid)
}
```


## First glimpse

The following chunk helps provide a first insight on what the dataset looks like.

`r button(text = "Description")` 
```{r}
dim(study_sample)

head(study_sample)
```
```{r}
tail(study_sample)
```
```{r}
glimpse(study_sample)
```
```{r}
summary(study_sample)
```

`r endbutton()` 

Revol and colleagues' (2024) step for renaming and relabeling step skipped here because it was completed in previous steps.

## Duplication



`r txt(id='esm-issue',title='Issue',text=" Participant #102 had two observations within a single observation 2-hr observation window due to a time-out issue. This issue arose when one of their surveys was interrupted and resent to the participant, but both the interrupted and the actual observation were saved. This interrupted observation contained no usable data.",FALSE)`

`r txt('esm-mod','Modification',"The following code removes the interrupted observation from participant 102 and revisits obsno summary to ensure Participant #102's max obsno == 60.")`

`r button(text = "Description")` 
```{r}
# Create obsno variable representing the serial order of observations within-participant
study_sample <- study_sample %>%
  arrange(participant_id, completion_time) %>%
  group_by(participant_id) %>%
  mutate(obsno = row_number()) %>%
  ungroup()

# Examine number of observations sent to participants
obsno_summary <- study_sample %>%
  group_by(participant_id) %>%
  summarise(
    max_obsno = max(obsno, na.rm = TRUE),
    n_rows = n()
  )
obsno_summary
```

```{r}
study_sample <- study_sample %>%
  filter(!(participant_id == 102 & session_id == 83))

obsno_summary <- study_sample %>%
  group_by(participant_id) %>%
  summarise(
    max_obsno = max(obsno, na.rm = TRUE),
    n_rows = n()
  )
obsno_summary
```

**Look for duplicated rows:** the dataframes do not have duplicated rows.
```{r}
sum(duplicated(study_sample))
```
```{r}
sum(duplicated(study_sample))
```

**Look for duplicated answers** (duplication in the self-reported items): no issue found regarding the number of self-reported items, the values of the variables involved, and the number of times duplicated.

```{r}
study_sample[!is.na(study_sample$init_time),] %>% # Select answered observations
    select(mood:pleasant) %>%  # Select self-report items
    group_by_all() %>%
    summarise(n = n()) %>% # Compute number of similar self-reported item values
    filter(n > 1) %>% arrange(desc(n)) %>% as.data.frame()
```


```{r}
# Check for duplicated answers based on key variables
answer_cols <- c("participant_id", "mood", "smoke", "before_survey", 
                 "unpleasant", "prior_mood", "smoked_since_last_survey", 
                 "pleasant", "session_id", "completion_time", "init_time")

dup_answers <- study_sample %>%
  group_by(across(all_of(answer_cols))) %>%
  filter(n() > 1) %>%
  ungroup()

cat("Duplicated answer sets:", nrow(dup_answers), "\n")
```

`r endbutton()` 

## Branching items

No issues detected.

`r button(text = "Description")` 

**Branching items are consistent:**

- when the participant chooses 'It was generally pleasant' for the variable 'before_survey', the variable  'pleasant' is displayed to the participant.
- when the participant chooses 'It was generally unpleasant' for the variable 'before_survey', the variable  'unpleasant' is displayed to the participant.

```{r}
# Check branching integrity for pleasant/unpleasant display
branch_check <- study_sample %>%
  mutate(
    both_missing = is.na(pleasant) & is.na(unpleasant),
    pleasant_display_error = (before_survey != "It was generally pleasant") & !is.na(pleasant),
    unpleasant_display_error = (before_survey != "It was generally unpleasant") & !is.na(unpleasant),
    neutral_response = before_survey == "It was generally neutral",
    before_missing = is.na(before_survey)
  ) %>%
  summarise(
    n_both_missing = sum(both_missing, na.rm = TRUE),
    n_neutral = sum(neutral_response, na.rm = TRUE),
    n_before_missing = sum(before_missing, na.rm = TRUE),
    neutral_plus_missing = n_neutral + n_before_missing,
    n_pleasant_display_error = sum(pleasant_display_error, na.rm = TRUE),
    n_unpleasant_display_error = sum(unpleasant_display_error, na.rm = TRUE)
  )

branch_check
```

Branching integrity was confirmed, as all observations with both pleasant and unpleasant missing corresponded exactly to n of 'neutral' or missing observations 'before_survey' responses, and no cases were identified in which a branch variable was displayed when its corresponding condition was not selected or in which both branch variables were simultaneously present.

`r endbutton()` 

# Check variable coherence
No issues detected.

`r button(text = "Description")` 

# **Consistency of time-invariant variables.**
```{r}
study_sample %>%
  group_by(participant_id) %>%
  summarise(n_age_values = n_distinct(age)) %>%
  filter(n_age_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_race_values = n_distinct(race)) %>%
  filter(n_race_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_gender_values = n_distinct(gender)) %>%
  filter(n_gender_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_total_household_income_values = n_distinct(total_household_income)) %>%
  filter(n_total_household_income_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_panas_pos_values = n_distinct(panas_pos)) %>%
  filter(n_panas_pos_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_panas_neg_values = n_distinct(panas_neg)) %>%
  filter(n_panas_neg_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_bank_balance_values = n_distinct(bank_balance)) %>%
  filter(n_bank_balance_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_ftnd_sum_values = n_distinct(ftnd_sum)) %>%
  filter(n_ftnd_sum_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_cigsperday_values = n_distinct(cigsperday)) %>%
  filter(n_cigsperday_values > 1)
```

`r endbutton()` 

## First missing values analysis

Here, our goal is to gain an overview of the patterns of missing values and address any preliminary issues related to them.
The following plot gives an overview of the missing values in the dataframe.

## Overview of missing values

```{r, fig.width=8, fig.height=10}
library(ggplot2)

data <- study_sample %>% 
  arrange(participant_id, completion_time)

vis_miss(study_sample) +
  theme(
    plot.margin = margin(t = 10, r = 10, b = 10, l = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

We can see multiple patterns and some missingness among the EMA variables.

We can get a sense for patterns of missingness by identifying the potential relationships or dependencies in missing values between variables (bottom) and the occurrences of each pattern (top).
```{r}
gg_miss_upset(study_sample)
```

Skipped Revol & colleagues' (2024) step to check coherence of missing values in the variables of interest because what would go here -- the missingness pattern between 'before_survey', 'pleasant', and 'unpleasant' was already examined above. 

# Create time variables

Our analyses require the creation of time-related variables. We already created the 'obsno' variable above, which represents the serial order in which a given observation occurs. 

`r txt('esm-mod','Modification',"In addition to creating the 'obsno' variable earlier we also create 'dayno' (day since first beep was sent), 'duration' (total length of one's participation), and 'beepno' which is the observation number within a given day.")`

`r button(text = "Description")` 
```{r}
study_sample <- study_sample %>%
  
  arrange(participant_id, completion_time) %>%
  
  group_by(participant_id) %>%
  
  mutate(
    # Time components
    year   = year(completion_time),
    month  = month(completion_time),
    day    = day(completion_time),
    hour   = hour(completion_time),
    minute = minute(completion_time),
    
    
    # Day number since first beep (day-level)
    dayno = as.numeric(
      difftime(
        as.Date(completion_time),
        as.Date(min(completion_time, na.rm = TRUE)),
        units = "days"
      )
    ) + 1,
    
    # Study duration in days (time-invariant)
    duration = as.numeric(
      difftime(
        as.Date(max(completion_time, na.rm = TRUE)),
        as.Date(min(completion_time, na.rm = TRUE)),
        units = "days"
      )
    ) + 1
  ) %>%
  
  ungroup() %>%
  
  # Beep number within day
  group_by(participant_id, dayno) %>%
  mutate(beepno = row_number()) %>%
  ungroup()

```

`r endbutton()` 

Flag (in)valid observations: Revol et. al. (2024)'s steps for validity checks were completed above. Skipped here.

# Step 2: Design and sample scheme checking

This section is dedicated to checking and solving issues due to inconsistencies between the planned and the actual design of the study.

## Calendar

Overview when the beeps were completed in a calendar format

`r button(text = "Description")` 
```{r}
study_sample %>%
  filter(!is.na(completion_time)) %>%    
  mutate(
    year = year(completion_time),
    month = month(completion_time),
    day = day(completion_time)
  ) %>%
  group_by(year, month, day) %>%
  summarise(n_beeps = n(), .groups = "drop") %>%
  ggplot(aes(x = month, y = day, fill = n_beeps)) +
  geom_tile(color = "grey80") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  facet_wrap(~year, ncol = 2) +
  scale_y_reverse() +
  labs(
    title = "Calendar of Beeps Across 4 Years of Data Collection",
    x = "Month",
    y = "Day",
    fill = "N Beeps"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```
`r endbutton()` 

## Sampling scheme plot and quantity of completed beeps

We proceed to the checking of the actual sample scheme and compare it to the defined one. 
```{r, warning=FALSE, message=FALSE}
study_sample %>%
  filter(!is.na(completion_time)) %>%
  mutate(
    weekday_type = ifelse(wday(completion_time, week_start = 1) %in% c(6,7), "weekend", "weekday")
  ) %>%
  group_by(participant_id, dayno, weekday_type) %>%
  summarise(n_beeps = n(), .groups = "drop") %>%
  ggplot(aes(x = factor(participant_id), y = factor(dayno))) +
  geom_point(aes(color = factor(n_beeps), shape = weekday_type), size = 1.5) +  # smaller points
  scale_color_brewer(palette = "Set2") +
  theme_minimal(base_size = 8) +  # smaller base text size
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 6),
    axis.text.y = element_text(size = 6),
    legend.text = element_text(size = 7),
    legend.title = element_text(size = 8)
  ) +
  labs(
    title = "Sampling scheme plot of completed EMA beeps",
    x = "Participant ID",
    y = "Cumulative Day",
    color = "Number of completed beeps",
    shape = "Day type"
  ) 
```

Here we can see that week(end) days are unevenly distributed across participants, that participants who skip a survey one day tend to skip a survey on another day, and that compliance is generally good across participants (note: participant #363 was included in this sample even though they have 0 observations for day 3/3 of their participation).

```{r}
# Examine number of completed beeps per participant
study_sample %>%
  group_by(participant_id) %>% 
  summarize(n_completed_beeps = n(), .groups = "drop") %>%
  ggplot(aes(x = factor(participant_id), y = n_completed_beeps)) +
    geom_col(position = "dodge", fill = "steelblue") +
    scale_y_continuous(breaks = seq(0, max(study_sample$obsno, na.rm = TRUE), 5)) +
    labs(
      title = "Number of completed beeps per participant",
      x = "Participant ID",
      y = "Completed beeps"
    ) +
    theme_minimal(base_size = 10) +  # smaller base font size
    theme(
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
      plot.title = element_text(face = "bold", size = 12)
    )
```

## Coherence timestamps

No issues detected.

`r button(text = "Description")` 

We check whether there is timestamp incoherence within observations (e.g., an observation with 'start' time after the 'end' time) or between observations (e.g., an observation that was scheduled after another one but with a 'start' time that is before).
```{r}
# Select and order relevant variables
df <- study_sample[, c("participant_id", "obsno",
                       "init_time", "completion_time")]

df <- df[order(df$participant_id, df$obsno), ]


# Timestamp coherence within observations

df %>%
  group_by(participant_id) %>%
  mutate(
    end_before_start = completion_time < init_time
  ) %>%
  filter(end_before_start) %>%
  ungroup() %>%
  as.data.frame()


# Timestamp coherence between observations

df %>%
  filter(!is.na(init_time), !is.na(completion_time)) %>%
  group_by(participant_id) %>%
  mutate(
    prev_completion = lag(completion_time),
    overlap_issue = prev_completion > init_time
  ) %>%
  filter(overlap_issue) %>%
  ungroup() %>%
  as.data.frame()

```

`r endbutton()` 

Revol et. al.'s (2024) steps to examine time and delay to send steps were not possible with our dataset, given we lack a 'sent' variable. These steps were designed to determine whether the survey sending timing adhered to the sampling scheme, and the tests that are feasible in our dataset indicate the sampling scheme was adhered to. 

# Step 3: Participants' response behaviors

This section is dedicated to investigating how well participants engaged with the ESM study looking particularly for problematic patterns of behaviors (e.g., invalid observations, response time, careless responding).

## Sampling scheme, quantity of beeps and time started

No issues detected.

`r button(text = "Supplementary")` 

We check how well participants followed the sampling scheme.

Sampling Scheme plot: this plot illustrates the start times of participants’ valid observations. The x-axis represents the observation number and the y-axis shows the distribution across weekdays and weekends. 

```{r}
study_sample %>%
  # Compute validity dynamically using the function
  mutate(valid = check_validity(.)) %>%
  filter(valid == 1) %>%
  mutate(
    weekday = ifelse(
      wday(init_time, week_start = 1) %in% c(6, 7),
      "weekend",
      "weekday"
    )
  ) %>%
  ggplot(aes(x = obsno, y = factor(participant_id))) +
  geom_point(aes(color = weekday), size = 1) +
  labs(
    title = "Sampling scheme of the valid observations",
    y = "Participant id",
    x = "Observation number"
  )
```

We check the volume of valid observations over time.

```{r}
# Number of valid response over 'obsno'
study_sample %>% 
   mutate(valid = check_validity(.)) %>%
  filter(valid==1) %>% 
  group_by(obsno) %>% summarize(n = n()) %>%
  ggplot(aes(x=obsno,y=n)) +
      geom_col(position = "dodge") +
        labs(title="Number of valid response over obsno",
             y="Number of valid beeps",x="Observation number")
```
```{r}
# Time of day beeps were started and (and valid)
study_sample %>%
   mutate(valid = check_validity(.)) %>%
  filter(valid == 1) %>%
  mutate(
    weekday = ifelse(
      wday(init_time, week_start = 1) %in% c(6, 7),
      "weekend",
      "weekday"
    ),
    time_of_day = hms::as_hms(init_time)
  ) %>%
  ggplot(aes(x = time_of_day)) +
  geom_histogram(bins = 100) +
  scale_x_time(breaks = scales::date_breaks("1 hour")) +
  facet_grid(weekday ~ .) +
  labs(
    title = "Time of day the beeps were started (and valid)",
    y = "Quantity of beeps started and valid",
    x = "Time of day"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

`r endbutton()` 

## Number of interactions

No issue detected. 

`r button(text = "Supplementary")` 

**Hour at which the beeps were started (in blue) and missed (in red):**
```{r}
df_interact <- study_sample %>%
  # Compute validity using the function
  mutate(valid = check_validity(.)) %>%
  mutate(
    hour = hour(init_time),
    sent_ = !is.na(init_time),
    weekday = ifelse(wday(init_time, week_start = 1) %in% c(6, 7), "weekend", "weekday")
  ) %>%
  group_by(hour, weekday) %>%
  summarise(
    interact = sum(valid),
    open = sum(sent_)
  ) %>%
  mutate(not_interact = open - interact) %>%
  tidyr::pivot_longer(cols = c(interact, not_interact), names_to = "type", values_to = "value")

df_interact %>%
  mutate(type = factor(type, levels = c("not_interact", "interact"))) %>%
  ggplot(aes(x = factor(hour), y = value, fill = type)) +
  geom_col(position = "stack") +
  facet_grid(weekday ~ .) +
  labs(
    title = "Number of interactions and non-interactions with the questionnaire by hour",
    y = "Number of beeps",
    x = "Hour of day",
    fill = "Interaction"
  )
```

`r endbutton()` 

## Delays

Compute delay to fill  variables. Revol & colleagues' (2024) preprocessing steps for computing delay to fill is not possible because we lack a 'sent' variable. Yet, we can still see most of the valid surveys are submitted in under five minutes, which is expected. 

`r button(text = "Supplementary")` 

```{r}
study_sample <- study_sample %>%
   mutate(valid = check_validity(.)) %>%
  mutate(
    daily_end_min   = as.numeric(difftime(completion_time, init_time, units = "mins"))
  )

study_sample %>%
  filter(valid == 1 & !is.na(daily_end_min)) %>%
  ggplot(aes(x = daily_end_min)) +
    geom_histogram(bins = 100, fill = "steelblue", color = "black") +
    labs(
      title = "Histogram of questionnaire durations (valid beeps)",
      y = "Number of beeps",
      x = "Duration in minutes"
    )
```


`r endbutton()` 

## Interval 2 beeps

No issues detected.

`r button(text = "Supplementary")` 

```{r}
# Compute time intervals between consecutive beeps within a day
study_sample_intervals <- study_sample %>%
   mutate(valid = check_validity(.)) %>%
  filter(valid == 1) %>% 
  arrange(participant_id, obsno) %>%
  group_by(participant_id, dayno) %>%
  mutate(time_int = as.numeric(difftime(lead(init_time), init_time, units = "mins"))) %>%
  ungroup()

# Plot histogram of intra-day beep intervals
study_sample_intervals %>%
  filter(!is.na(time_int)) %>%  # remove last beep in each day (no next beep)
  ggplot(aes(x = time_int)) +
    geom_histogram(bins = 100, fill = "steelblue", color = "black") +
  scale_x_continuous(limits = c(0, 1500)) +  # limit x-axis to 0–1500 mins
    labs(
      title = "Histogram of delays between two subsequent beeps within a day",
      y = "Number of beeps",
      x = "Delay (minutes)"
    )
```

`r endbutton()` 

## Compliance Rate

We computed participant compliance as the proportion of valid EMA observations out of the maximum possible prompts per participant. For participants who only completed Part 2 of the parent study, max obsno == 18. For participants who completed the Parts 2 and 6,of the parent study, max obsno == 60. We apply the valid function from earlier to only consider valid observations in our compliance calculation. 

`r button(text = "Supplementary")`

```{r}
#Compliance audit
compliance_df <- study_sample %>%
  group_by(participant_id) %>%
  summarise(
    valid_beeps = sum(valid, na.rm = TRUE),
    max_dayno   = max(dayno, na.rm = TRUE),
    max_obs     = if_else(max_dayno <= 3, 18, 60),
    compliance  = valid_beeps / max_obs
  )
compliance_audit <- study_sample %>%
  group_by(participant_id) %>%
  summarise(
    valid_beeps = sum(valid, na.rm = TRUE),
    max_dayno   = max(dayno, na.rm = TRUE),
    total_possible = if_else(max_dayno <= 3, 18, 60),
    completion_group = if_else(max_dayno <= 3, "Part 2 Only (3 days)", 
                                "Part 2 + 6 (10 days)"),
    compliance = valid_beeps / total_possible
  ) %>%
  ungroup()

#View compliance audit results
ggplot(compliance_df, aes(x = compliance)) +
  geom_histogram(binwidth = 0.05, boundary = 0) +
  scale_x_continuous(
    limits = c(0, 1),
    breaks = seq(0, 1, by = 0.1),
    labels = scales::percent_format(accuracy = 1)
  ) +
  labs(
    title = "Distribution of Participant Compliance",
    x = "Compliance (% of possible EMA prompts)",
    y = "Number of Participants"
  ) +
  theme_minimal()
compliance_audit %>%
  group_by(completion_group) %>%
  summarise(
    n_participants = n(),
    mean_valid = mean(valid_beeps),
    mean_possible = mean(total_possible),
    mean_compliance = mean(compliance),
    min_compliance = min(compliance),
    max_compliance = max(compliance)
  )

```

`r endbutton()` 

# Step 4: Compute and transform variables

This section is dedicated to computing and modifying variables of interest that will later be used in visualization and statistical analysis.

`r txt('esm-mod','Modification',"Person-level mean and person-mean-centered versions of variables that will be used in analyses.")` 
```{r}
# Variables to process
vars <- c("mood", "smoke", "unpleasant", "prior_mood", "pleasant")

study_sample <- study_sample %>%
  group_by(participant_id) %>%  # compute within each person
  mutate(
    across(all_of(vars), ~ mean(.x, na.rm = TRUE), .names = "{.col}_pm"),  # person mean (between-person)
    across(all_of(vars), ~ .x - mean(.x, na.rm = TRUE), .names = "{.col}_pmc")  # person-mean centered (within-person)
  ) %>%
  ungroup()
```

`r txt('esm-inspect','Inspection',"Preproessed dataset meta-info:",FALSE)` 
```{r}
cat("## Path      : in-memory dataframe\n")
cat("## Extension : RDS (original format, now in-memory)\n")
cat("## Size      :", format(object.size(study_sample), units = "auto"), "\n\n")

# Dimensions
cat("## ncol      :", ncol(study_sample), "\n")
cat("## nrow      :", nrow(study_sample), "\n\n")

# Number of participants
id_var <- "participant_id"
n_participants <- n_distinct(study_sample[[id_var]])
cat("## Number of participants :", n_participants, "\n")

# Average number of observations per participant
avg_obs <- nrow(study_sample) / n_participants
cat("## Average number of observations per participant :", round(avg_obs, 1), "\n\n")

# Time period
time_var <- "init_time"
if(time_var %in% names(study_sample)) {
  time_min <- min(study_sample[[time_var]], na.rm = TRUE)
  time_max <- max(study_sample[[time_var]], na.rm = TRUE)
  cat("## Period : from", format(time_min, "%Y-%m-%d %H:%M:%S"),
      "to", format(time_max, "%Y-%m-%d %H:%M:%S"), "\n\n")
} else {
  cat("## Period : init_time variable not found in dataset\n\n")
}

# Variable names
cat("## Variables :", paste(names(study_sample), collapse = ", "), "\n")
```
```{r}
# Save the study_sample dataframe as an RDS file
saveRDS(study_sample, file = here("output", "cleaned_study_sample.RDS"))
```

#Revol, J., Carlier, C., Lafit, G., Verhees, M., Sels, L., & Ceulemans, E. (2024). Preprocessing ESM data: a step-by-step framework, tutorial website, R package, and reporting templates.

