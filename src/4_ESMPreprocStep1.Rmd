---
title: "EMA Preprocessing (Revol et. al. 2024 Steps 1 - 4)"
author:
  - name: Walter G. Dyer, wdyer@psu.edu, Penn State University
date: "`r Sys.Date()`"
output: 
  html_document:
      toc: true
      number_sections: false
      toc_float: true
      toc_depth: 2
---

<!-- Javascript code to zoom in and out in the plots. -->s
<!-- Code from Radovan Miletić: https://stackoverflow.com/questions/56361986/zoom-function-in-rmarkdown-html-plot -->
<script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
    $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
    $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
    $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
});
</script>


# Overview and data collection procedure

This R Markdown file is based on Revol et al. (2024)'s step-by-step guidelines for preprocessing ESM data: [https://preprocess.esmtools.com](https://preprocess.esmtools.com). It includes code adapted from Steps 1 - 5, tailored to preprocess EMA data for a secondary analysis of EMA data from the DVAL project (https://osf.io/nb9ct/overview?view_only=4f777b3907bb47aab6387aaa4353285c. In part2 of the study, participants recieved semi-random prompts 6 times throughout the day within predeterimined 2-hr intervals for three consecutive days. 

---
# Load packages

Import the packages:
```{r, message=FALSE, warning=FALSE}

#Data management
library(dplyr)
library(tidyr)
library(data.table)
library(here)
library(readr)   
library(readxl)
library(esmtools) # For button(), txt() functions

# Descriptive statistics
library(skimr)

# Missing values inspection
library(naniar)
library(visdat)

# Plotting
library(ggplot2)

# Character manipulation
library(stringr)
library(janitor)

# Dates and times
library(lubridate)
library(hms)
```

# Step 1: Import data and preliminary preprocessing

This section is dedicated to the first look at the data, the merging of data sources the first basic preprocessing methods (e.g., duplicates, branching items check), and checking the variable consistency when the data has just been imported.

Import the data: 
```{r}
#Define path to EMA Part 2 data
part2_path <- here("data", "DVAL_EMA_Part2_beeped.csv")
```

Raw dataset meta-info:
```{r}
dataInfo(file_path = part2_path, 
         read_fun = read.csv,
         idvar = "participant_id", 
         timevar = "init_time")
```
# Import data and prepare for preprocessing steps

Below are several steps that will facilitate the application of Revol et al's preprocessing steps. Specifically, only variables and participants relevant to the study will be included in the preprocessing steps, so the data must be subset. Additionally, how to define missing values is specified, variables are formatted to their respective types (e.g., numeric, character), and formatting issues related to cases where participants opted out of a survey are dealt with below. 

## Modification text:data are subsetted to include only participants who completed Part2 (3 days of EMA data collection
```{r}
# Define subset of participants who completed Part2 (3 days of EMA data collection)
subset_ids <- c(
  102, 104, 107, 112, 113, 115, 116, 124, 125, 126, 127, 128, 133, 141, 
  150, 151, 154, 159, 163, 164, 166, 169, 175, 177, 180, 186, 188, 192, 
  195, 196, 197, 198, 199, 202, 206, 209, 210, 213, 214, 216, 218, 221, 
  222, 223, 233, 238, 240, 246, 252, 257, 262, 268, 273, 274, 278, 281, 
  282, 286, 287, 290, 291, 295, 297, 300, 301, 304, 310, 314, 320, 321, 
  329, 332, 340, 341, 342, 344, 346, 349, 351, 356, 362, 363, 369, 370, 
  372, 381, 383, 393, 394, 399, 416, 423, 427, 428, 430
)
```

## Issue text: The raw dataset is quite large and includes several variables irrelevant to this study. Additionally, missinginess is inconsistently coded upon data import.
## Modification text: EMA variables relevant to the study are extracted, and missingness is standardized across variables.

## Issue text: The variable smoked_since_last_survey gave participants the option to select '6+' which, while useful for other analyses, prevents us from formatting the variable as numeric.
## Modification text: The chunk below also converts '6+' to 6 for the variable smoked_since_last_survey.

## Issue text: Instances where participants opted out were reported by the literal text 'opted out' in the raw dataset, making the data incompatible with the command to format the variable as numeric.
## Modification text: In order to maintain these data but in a format compatible with numeric formatting, a variable to track opted out instances is created to check whether further actions to account for these cases must be taken.

## Issue text: Variables are all in character format upon import.
## Modification text: The below chunk also formats numeric variables as numeric.")`

Note: the below code also includes counts of missingness before and after the data modifications. No data were lost during the modification process.

```{r}
# Read in CSV 
part2beeped_raw <- read_csv(
  part2_path,
  na = c("-99", "__NA__", "NA", ""),
  col_types = cols(.default = col_character()),
  col_select = c(
    mood,
    smoke,
    before_survey,
    unpleasant,
    prior_mood,
    smoked_since_last_survey,
    pleasant,
    participant_id,
    session_id,
    completion_time,
    init_time
  )
) %>%
  filter(as.numeric(participant_id) %in% subset_ids)
```

```{r}
# Check frequency of "opted out"
vars_to_check <- c(
  "mood", "smoke", "unpleasant", "pleasant",
  "prior_mood", "smoked_since_last_survey",
  "participant_id", "session_id"
)

opted_out_counts <- part2beeped_raw %>%
  summarise(across(
    all_of(vars_to_check),
    ~ sum(. == "opted out", na.rm = TRUE)
  )) %>%
  tidyr::pivot_longer(
    everything(),
    names_to = "variable",
    values_to = "n_opted_out"
  ) %>%
  arrange(desc(n_opted_out))

opted_out_counts
```

```{r}
# Record missingness BEFORE conversion
missing_before <- part2beeped_raw %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  tidyr::pivot_longer(
    everything(),
    names_to = "variable",
    values_to = "missing_before"
  )
```

# Prepare numeric variables for recoding and recode numeric variables

```{r}
part2beeped <- part2beeped_raw %>%
  mutate(
    across(
      c(smoked_since_last_survey, mood, smoke, unpleasant,
        pleasant, prior_mood, participant_id, session_id),
      ~ trimws(.)
    ),
    
#Recode smoked_since_last_survey
    smoked_since_last_survey = case_when(
      smoked_since_last_survey == "6+" ~ "6",  # convert 6+ to 6
      TRUE ~ smoked_since_last_survey
    ),
    smoked_since_last_survey = suppressWarnings(
      as.numeric(smoked_since_last_survey)
    ),
    
#Recode mood, addressing the opted out case
    mood = ifelse(mood == "opted out", NA, mood),
    mood = suppressWarnings(as.numeric(mood)),
    
#Format all other numeric variables
    smoke = suppressWarnings(as.numeric(smoke)),
    unpleasant = suppressWarnings(as.numeric(unpleasant)),
    pleasant = suppressWarnings(as.numeric(pleasant)),
    prior_mood = suppressWarnings(as.numeric(prior_mood)),
    participant_id = suppressWarnings(as.numeric(participant_id)),
    session_id = suppressWarnings(as.numeric(session_id))
    
  )
```

```{r}
# Record missingness AFTER conversion
missing_after <- part2beeped %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  tidyr::pivot_longer(
    everything(),
    names_to = "variable",
    values_to = "missing_after"
  )
```

# Inspect
```{r}
missing_summary <- missing_before %>%
  left_join(missing_after, by = "variable") %>%
  arrange(variable)

missing_summary
```
Missingness increased by one case for 'mood' when the opted out data were converted to NA. Because the opportunity to examine this aspect of response behavior was nonexistent in this sample, the decision was made to simply recode the data to missing (i.e., NA).

# Modification text: format time variables as POSIXct."
```{r}
part2beeped <- part2beeped %>%
  mutate(init_time = as.POSIXct(init_time, tz = "UTC"),
         completion_time = as.POSIXct(completion_time, tz = "UTC"))
```

Cleaned dataset meta-info:
```{r}
# Basic info
cat("## Path      : in-memory dataframe\n")
cat("## Extension : RDS\n")
cat("## Size      :", format(object.size(part2beeped), units = "auto"), "\n")

# Dimensions
cat("## ncol      :", ncol(part2beeped), "\n")
cat("## nrow      :", nrow(part2beeped), "\n")

# Number of participants
id_var <- "participant_id"
n_participants <- n_distinct(part2beeped[[id_var]])
cat("## Number participants :", n_participants, "\n")

# Average number of observations per participant
avg_obs <- nrow(part2beeped) / n_participants
cat("## Average number obs :", round(avg_obs, 1), "\n")

# Time period
time_var <- "init_time"
time_min <- min(part2beeped[[time_var]], na.rm = TRUE)
time_max <- max(part2beeped[[time_var]], na.rm = TRUE)
cat("## Period : from", format(time_min, "%Y-%m-%d %H:%M:%S"), 
    "to", format(time_max, "%Y-%m-%d %H:%M:%S"), "\n")

# Variable names
cat("## Variables :", paste(names(part2beeped), collapse = ", "), "\n")
```
The EMA data are now prepared for Revol et. al.'s preprocessing workflow but must be merged with the parent study's baseline dataset for time-invariant variables (e.g., covariates). The below code 

#Modification text: Baseline variables are preprocessed according to survey author guidelines (see parent study online repository for full list of baseline measures) and planned analyses.
```{r}
# Define paths to input data
Apath <- here("data", "QuestionnairesA.xlsx")
Bpath <- here("data", "QuestionnairesB.xlsx")

# Read files into dataframes
A <- read_excel(Apath)
B <- read_excel(Bpath)

# Merge the baseline datasets
baseline <- merge(A, B, by = "participant-id", all = TRUE, suffixes = c(".A", ".B"))

# Clean column names (lowercase, underscores instead of hyphens)
baseline <- clean_names(baseline)

# Filter to participants who completed Part 2 EMA
analytic_sample <- c(102, 104, 107, 112, 113, 115, 116, 124, 125, 126, 127, 128, 133, 141, 150, 151, 154, 159, 163, 164, 166, 169, 175, 177, 180, 186, 188,
192, 195, 196, 197, 198, 199, 202, 206, 209, 210, 213, 214, 216, 218, 221, 222, 223, 233, 238, 240, 246, 252, 257, 262, 268, 273, 274, 278, 281, 282, 286, 287, 290, 291, 295, 297, 300, 301, 304, 310, 314, 320, 321, 329, 332, 340, 341, 342, 344, 346, 349, 351, 356, 362, 363, 369, 370, 372, 381, 383, 393, 394, 399, 416, 423, 427, 428, 430)
baseline <- baseline %>% filter(participant_id %in% analytic_sample)

# ---- FTND: Fagerstrom ----
baseline <- baseline %>%
  rename(cigsperday = ftnd_4) %>%
  mutate(ftnd_4 = case_when(
    cigsperday <= 10 ~ 1,
    cigsperday > 10 & cigsperday <= 20 ~ 2,
    cigsperday > 20 & cigsperday <= 30 ~ 3,
    cigsperday > 30 ~ 4
  )) %>%
  mutate(ftnd_sum = ftnd_1 + ftnd_2 + ftnd_3 + ftnd_4 + ftnd_5 + ftnd_6)

# ---- PANAS: Positive and Negative Affect Schedule ----
baseline <- baseline %>%
  mutate(
    panas_pos = q64_pan_1 + q64_pan_3 + q64_pan_5 + q64_pan_9 + q64_pan_10 + q64_pan_12 + q64_pan_14 + q64_pan_16 + q64_pan_17 + q64_pan_19,
    panas_neg = q64_pan_2 + q64_pan_4 + q64_pan_6 + q64_pan_7 + q64_pan_8 + q64_pan_11 + q64_pan_13 + q64_pan_15 + q64_pan_18 + q64_pan_20
  )

# ---- SHAPS: Snaith-Hamilton Pleasure Scale ----
baseline <- baseline %>%
  mutate(across(starts_with("q14_sha_"), ~ ifelse(. %in% c(1,2), 1, 0), .names = "{.col}_sim")) %>%
  mutate(shaps_sim_sum = q14_sha_1_sim + q14_sha_2_sim + q14_sha_3_sim + q14_sha_4_sim + q14_sha_5_sim + q14_sha_6_sim + 
           q14_sha_7_sim + q14_sha_8_sim + q14_sha_9_sim + q14_sha_10_sim + q14_sha_11_sim + q14_sha_12_sim + 
           q14_sha_13_sim + q14_sha_14_sim)

# ---- Reformat column types ----
change_column_types <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    if (is.numeric(col_data) || inherits(col_data, "POSIXct")) next
    if (is.character(col_data)) {
      trimmed <- trimws(col_data)
      numeric_check <- suppressWarnings(!is.na(as.numeric(trimmed)))
      if (all(numeric_check | is.na(trimmed))) {
        df[[col_name]] <- as.integer(trimmed)
      } else {
        df[[col_name]] <- trimmed
      }
    }
  }
  # Convert date columns
  for (col_name in colnames(df)) {
    if (grepl("_date_", col_name)) {
      df[[col_name]] <- as.POSIXct(df[[col_name]], format = "%m/%d/%Y")
    }
  }
  return(df)
}
baseline <- change_column_types(baseline)

# ---- Fix column name typo ----
baseline <- baseline %>% rename(total_household_income = total_houselhold_income)

# ---- Subset to analysis-relevant variables ----
baseline_clean <- baseline %>%
  select(
    participant_id,
    race,
    age,
    gender,
    total_household_income,
    bank_balance,
    ftnd_sum,
    cigsperday,
    shaps_sim_sum,
    panas_pos,
    panas_neg
  )
```
'baseline_clean' is the dataframe with all baseline variables, now prepared for merging with the EMA data.

##Issue text: the EMA data alone do not contain all participant data needed for analyses. They must be combined with baseline data.
##Modification text: The EMA and Baseline Data are merged, and baseline variables listed after the EMA variables.

```{r}
# Specify baseline variables
baseline_vars <- c(
  "race",
  "age",
  "gender",
  "total_household_income",
  "bank_balance",
  "ftnd_sum",
  "cigsperday",
  "shaps_sim_sum",
  "panas_pos",
  "panas_neg"
)

# Merge and reorder in a single step
study_sample <- part2beeped %>%
  left_join(baseline_clean, by = "participant_id") %>%
  select(
    # All columns except the baseline variables first
    -all_of(baseline_vars),
    # Then baseline variables at the end
    all_of(baseline_vars)
  )

# Optional: inspect the first few rows and column order
head(study_sample)
colnames(study_sample)
```

study_sample meta-info:

```{r}
cat("## Path      : in-memory dataframe\n")
cat("## Extension : RDS (original format, now in-memory)\n")
cat("## Size      :", format(object.size(study_sample), units = "auto"), "\n\n")

# Dimensions
cat("## ncol      :", ncol(study_sample), "\n")
cat("## nrow      :", nrow(study_sample), "\n\n")

# Number of participants
id_var <- "participant_id"
n_participants <- n_distinct(study_sample[[id_var]])
cat("## Number of participants :", n_participants, "\n")

# Average number of observations per participant
avg_obs <- nrow(study_sample) / n_participants
cat("## Average number of observations per participant :", round(avg_obs, 1), "\n\n")

# Time period
time_var <- "init_time"
if(time_var %in% names(study_sample)) {
  time_min <- min(study_sample[[time_var]], na.rm = TRUE)
  time_max <- max(study_sample[[time_var]], na.rm = TRUE)
  cat("## Period : from", format(time_min, "%Y-%m-%d %H:%M:%S"),
      "to", format(time_max, "%Y-%m-%d %H:%M:%S"), "\n\n")
} else {
  cat("## Period : init_time variable not found in dataset\n\n")
}

# Variable names
cat("## Variables :", paste(names(study_sample), collapse = ", "), "\n")
```


## First glimpse

The following chunk helps to have a first insight on what the dataset looks like.

```{r}
dim(study_sample)
```
```{r}
head(study_sample)
```
```{r}
tail(study_sample)
```
```{r}
glimpse(study_sample)
```
```{r}
summary(study_sample)
```
```{r}
table(study_sample$before_survey, useNA="ifany")
```


## Duplication
No issues detected.

**Look for duplicated rows:** the dataframe does not have duplicated rows.
```{r}
sum(duplicated(study_sample))
```

**Look for duplicated answers** (duplication in the self-reported items): no issue found regarding the number of self-reported items, the values of the variables involved, and the number of times duplicated .

```{r}
study_sample[!is.na(study_sample$init_time),] %>% # Select answered observations
    select(mood:pleasant) %>%  # Select self-report items
    group_by_all() %>%
    summarise(n = n()) %>% # Compute number of similar self-reported item values
    filter(n > 1) %>% arrange(desc(n)) %>% as.data.frame()
```


```{r}
# Check for duplicated answers based on key variables
answer_cols <- c("participant_id", "mood", "smoke", "before_survey", 
                 "unpleasant", "prior_mood", "smoked_since_last_survey", 
                 "pleasant", "session_id", "completion_time", "init_time")

dup_answers <- study_sample %>%
  group_by(across(all_of(answer_cols))) %>%
  filter(n() > 1) %>%
  ungroup()

cat("Duplicated answer sets:", nrow(dup_answers), "\n")
```

## Branching items

**Branching items are consistent:**

- when the participant chooses 'It was generally pleasant' for the variable 'before_survey', the variable  'pleasant' is displayed to the participant.
- when the participant chooses 'It was generally unpleasant' for the variable 'before_survey', the variable  'unpleasant' is displayed to the participant.
- n of observations for which both 'unpleasant' and 'pleasant' are missing (N=648) correspond to the n of observations for which participants reported 'It was generally neutral' (N=549; above) plus the n missinenss for the 'before_survey' variable (N=99; above), indicating no problems occurred at this step.

```{r}
# Count the number of observations for each before_survey category
branch_check <- study_sample %>%
  mutate(
    # Flag cases where both numeric branching variables are missing
    both_missing = is.na(pleasant) & is.na(unpleasant)
  ) %>%
  summarise(
    n_pleasant_displayed = sum(!is.na(pleasant) & before_survey == "It was generally pleasant"),
    n_unpleasant_displayed = sum(!is.na(unpleasant) & before_survey == "It was generally unpleasant"),
    n_neutral_branch = sum(both_missing & before_survey == "It was generally neutral"),
    n_both_missing_total = sum(both_missing),
    total_obs = n()
  )

branch_check
```
# Check variable coherence
# **Consistency of time-invariant variables.**
```{r}
study_sample %>%
  group_by(participant_id) %>%
  summarise(n_age_values = n_distinct(age)) %>%
  filter(n_age_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_race_values = n_distinct(race)) %>%
  filter(n_race_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_gender_values = n_distinct(gender)) %>%
  filter(n_gender_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_total_household_income_values = n_distinct(total_household_income)) %>%
  filter(n_total_household_income_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_panas_pos_values = n_distinct(panas_pos)) %>%
  filter(n_panas_pos_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_panas_neg_values = n_distinct(panas_neg)) %>%
  filter(n_panas_neg_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_bank_balance_values = n_distinct(bank_balance)) %>%
  filter(n_bank_balance_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_ftnd_sum_values = n_distinct(ftnd_sum)) %>%
  filter(n_ftnd_sum_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_cigsperday_values = n_distinct(cigsperday)) %>%
  filter(n_cigsperday_values > 1)
```
No issues detected.



#Renaming and relabeling: step skipped here because it was completed in previous RMDs

#Flag (in)valid observations
```{r}
#Identify the number of started, but incomplete, surveys (0 = number of incomplete surveys across participants)
d$subm_time_valid = as.numeric(!is.na(d$time_complete))
table(d$subm_time_valid)
#Another option would be to examine the values for 'survey_status' across participants and view the overall compliance rate per participant.

survey_status_counts <- d %>%
  group_by(participant_id, survey_status) %>%
  summarise(count = n(), .groups = "drop") %>%
  pivot_wider(names_from = survey_status, values_from = count, values_fill = 0) %>%
  mutate(
    total_surveys = rowSums(across(-participant_id)),  # Sum all survey statuses
    incomplete_surveys = rowSums(across(any_of(c("Timed Out", "Skipped", "Interrupted")))),  
    compliance_rate = 1 - (incomplete_surveys / total_surveys)  # Percentage of completed
  ) 

print(survey_status_counts)
```
#Interpretation of the above step: Meta analysis (Jones et al, 2018) suggests using a cutoff of 70% compliance when selecting participants to include. However, we have options for accounting for high missingness within-person, so no exclusions have been made as of 5.19.25.

#Compute the number of items answered (no missing values) in each row among the variables of interest. Here, variables of interest reflect those central to the main paper for the DVAL study, in which easy_difficult and mood are the focus. (0 = zero non-missing values in selected columns, 1 = one non-missing value in selected columns, 2 = two non-missing values in selected columns, 3 = three non-missing values in selected columns). 
```{r}
d$var_of_interest_valid = rowSums(!is.na(dplyr::select(d, easy_difficult, mood, pleasant)))
table(d$var_of_interest_valid)
```
#Specify that a row must have non-missing data in all (2) selected columns in order to be considered valid. (This way we can include some surveys that were not technically submitted but still have data for our variables of interest). 
```{r}
threshold = 3
d$valid = as.numeric(d$var_of_interest_valid >= threshold)
table(d$valid)
```
#(Lots more that can be done with validity, this is currently what defines DVAL EMA validity as of 5.19.25)

#First missingness analysis of EMA items
#This section explores and handles missing values. Reformatting of variables has already occurred in the premerge RMDs, which took care of some of the issues that would have been captured in this section, such as missing values erroneously being represented by the text "NA". 

#This is an opportunity to check that the values are accurately coded. For R, missing values should be represented by "na".*********
```{r}
#describe(d)
```

#First, a visualization of the missingness in the dataset, where the y-axis represents observations and the x-axis the EMA variables in the dataset (note: the dataframe used here includes subsets of beeped EMA variables, because the combined dataset was too large).  

```{r} 

#Here, the beeped data are broken down into part2 (days 1 - 3) and part6 (days 4 - 10). 
part2 <- d %>%  
  filter(study_day >= 1 & study_day <= 3) 
part6 <- d %>%  
  filter(study_day >= 4 & study_day <= 10) 
``` 

```{r}
#Here, the beeped data are broken down into groups within part2 and part6.
##Define variable groups
current_state_vars <- c("happy", "dissatisfied", "irritable", "relaxed", "depressed", 
                        "mentally_exhausted", "elated", "stressed", "difficulty_concentrating", 
                        "health", "mood", "energy_level")

current_smok_vars <- c("smoke", "motivated", "confident", "pay", "easy_difficult")

prior_eventapp_vars <- c("before_survey", "pleasant", "neutral", "unpleasant")

other_eventapp_vars <- c("prior_mood", "pleasurable_activities", "stressful_occurrence", 
                         "how_stressful", "upcoming_activities")

context_vars <- c("location", "current_location", "smoking_now")

lagged_behavior_vars <- c("who_been_with", "physically_active", "smoked_since_last_survey", 
                          "consumed")
```

#Examine groups 
```{r}
current_state <- d %>% dplyr::select(participant_id, study_day, all_of(current_state_vars))
vis_miss(current_state) + ggtitle("Current_state_vars missingness")

current_smok <- d %>% dplyr::select(participant_id, study_day, all_of(current_smok_vars))
vis_miss(current_smok) + ggtitle("Missingness in part2 - current_smok_vars")

prior_eventapp <- d %>% dplyr::select(participant_id, study_day, all_of(prior_eventapp_vars))
vis_miss(prior_eventapp) + ggtitle("Missingness in part2 - prior_eventapp_vars")

other_eventapp <- d %>% dplyr::select(participant_id, study_day, all_of(other_eventapp_vars))
vis_miss(other_eventapp) + ggtitle("Missingness in part2 - other_eventapp_vars")

context <- d %>% dplyr::select(participant_id, study_day, all_of(context_vars))
vis_miss(part2_context) + ggtitle("Missingness in part2 - context_vars")

lagged_behavior <- d %>% dplyr::select(participant_id, study_day, all_of(lagged_behavior_vars))
vis_miss(lagged_behavior) + ggtitle("Missingness in part2 - lagged_behavior_vars")
```
#Next we can compute the number of missing values (or their percentage) per variable. 
```{r}
miss_var_summary(part2)
miss_var_summary(part6)
miss_var_summary(d)
```
#At this point, it would be helpful to be able to determine the numbers of missing values per observation and determine whether they are systematic or random.
#Here, the x-axis is the observation number and the y-axis represents the number of missing values within the variables of each observation. 
```{r}
gg_miss_case(part2)
gg_miss_case(part6)
gg_miss_case(d)
```
#From Revol et al, (2024)"We can explore missing values grouping by participants. However, it is a more complex exploration as missing values are now grouped in observations/variables which we nest within participants. We propose three methods:
#1. Occurrence of missing values: if observations contain either no or only missing values (in self-report items), we can use a variable to account for the number of missed beeps by the participant.
```{r fig.width=12, fig.height=6}
#easy_difficult
d %>%
  group_by(participant_id) %>%
  summarise(easy_difficult_miss = sum(is.na(easy_difficult))) %>%
  ggplot(aes(x=factor(participant_id), y=easy_difficult_miss)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + # Rotate x-axis labels if needed
  theme(plot.margin = unit(c(1, 1, 1, 1), "cm")) # Add extra margins if desired
# before_survey
d %>%
  group_by(participant_id) %>%
  summarise(before_survey_miss = sum(is.na(before_survey))) %>%
  ggplot(aes(x = factor(participant_id), y = before_survey_miss)) +
  geom_col() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, margin = margin(t = 5)), # Adds spacing
    plot.margin = unit(c(1, 1, 2, 1), "cm")  # Increases bottom margin
  )
# neutral
d %>%
  group_by(participant_id) %>%
  summarise(neutral_miss = sum(is.na(neutral))) %>%
  ggplot(aes(x=factor(participant_id), y=neutral_miss)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(plot.margin = unit(c(1, 1, 1, 1), "cm"))
# mood
d %>%
  group_by(participant_id) %>%
  summarise(mood_miss = sum(is.na(mood))) %>%
  ggplot(aes(x=factor(participant_id), y=mood_miss)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(plot.margin = unit(c(1, 1, 1, 1), "cm"))
# pleasant
d %>%
  group_by(participant_id) %>%
  summarise(pleasant_miss = sum(is.na(pleasant))) %>%
  ggplot(aes(x=factor(participant_id), y=pleasant_miss)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(plot.margin = unit(c(1, 1, 1, 1), "cm"))
# unpleasant
d %>%
  group_by(participant_id) %>%
  summarise(unpleasant_miss = sum(is.na(unpleasant))) %>%
  ggplot(aes(x=factor(participant_id), y=unpleasant_miss)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(plot.margin = unit(c(1, 1, 1, 1), "cm"))
```
#Sort dataframe by participant_id (numeric) order
```{r}
d <- d %>% arrange(participant_id)
```

#2. Occurrence of missing values within variables: we can investigate if missingness between variables is identical across participants. Hence, we want to visualize the occurrence of missing values within each variable for each participant. It is particularly relevant if participants were allowed to answer only part of the questionnaires.******
```{r fig.width=6, fig.height=10}
d %>%
  group_by(participant_id) %>%
  summarise(across(before_survey:unpleasant, ~ sum(is.na(.)), .names = "miss_{.col}")) %>% 
  pivot_longer(cols = -participant_id, names_to = "var", values_to = "occ") %>%
  ggplot(aes(x = factor(participant_id), y = occ, fill = var)) +
    geom_col(position = "identity") +
    coord_flip() +
    theme(axis.text.y = element_text(size = 6, margin = margin(r = 5)))  # Adjust right margin
```

#3.Occurrence of the number of missing values per row/observation: we investigate how the number of missing values per row/observation occurs within participants. It is particularly relevant if participants were allowed to answer only part of the questionnaires."
```{r fig.width=12, fig.height=6}
# Count missing values per row
d <- d %>%
  mutate(miss_gap = rowSums(is.na(.)))

n_ <- nrow(d)

# Limit to top 50 participants by number of rows
top_ids <- d %>%
  count(participant_id) %>%
  top_n(50, n) %>%
  pull(participant_id)

# Define numeric order for those participant IDs
top_ids_ordered <- top_ids[order(as.numeric(as.character(top_ids)))]

# Summarize and plot
d %>%
  filter(participant_id %in% top_ids) %>%
  group_by(miss_gap, participant_id) %>%
  summarise(
    n = n(),
    perc_n = n / n_,
    .groups = "drop"
  ) %>%
  ggplot(aes(x = factor(participant_id, levels = top_ids_ordered), 
             y = n, fill = factor(miss_gap))) +
    geom_col(position = "identity") +
    coord_flip() +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 7),
      axis.title.y = element_blank(),
      plot.title = element_text(hjust = 0.5),
      legend.position = "bottom",
      legend.text = element_text(size = 8)
    ) +
    guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
    labs(
      x = "Participant ID",
      y = "Number of Observations",
      fill = "Missing per Row"
    ) +
    ggtitle("Distribution of Missing Data by Participant and Row")
```


#Correlates. The below code helps to identify potential dependencies or relationships in missing values between variables, and investigate variables potentially influencing missingness (note: in the DVAL main study, this would be relevant for before_survey, pleasant, and unpleasant).
#From Revol et al, (2024): "The ‘gg_miss_upset()’ function enables us to visualize the overlap and combinations of missing values across different variables. The lower part of the plot showcases the distinct patterns of missingness between variables, while the upper plot depicts the occurrences of each of these patterns. "

```{r}
gg_miss_upset(d)
```

#Create obsno variable that indicates the serial order of the beeps for each participant. 
```{r}
#Generate a complete skeleton for expected beeps
# Define number of expected study days and beeps per day
n_days <- 10
n_beeps <- 6

# Get all participant IDs
participant_ids <- unique(d$participant_id)

# Create the skeleton of expected beeps
skeleton <- expand.grid(
  participant_id = participant_ids,
  study_day = 1:n_days,
  beep_in_day = 1:n_beeps
) %>%
  arrange(participant_id, study_day, beep_in_day) %>%
  group_by(participant_id) %>%
  mutate(obsno = row_number()) %>%
  ungroup()

#Merge original dataset into skeleton
# Add row number per day in the original data (for merging)
d <- d %>%
  arrange(participant_id, study_day, completion_time) %>%
  group_by(participant_id, study_day) %>%
  mutate(beep_in_day = row_number()) %>%
  ungroup()
d_full <- skeleton %>%
  left_join(d, by = c("participant_id", "study_day", "beep_in_day"))
#Ensure the obsno variable was accurately created (Key: that missing observations remain in their serial order)
d_full %>%
  dplyr::select(participant_id, completion_time, study_day, obsno) %>%
  arrange(participant_id, obsno) %>%
  print(n = 100)
```

#Continuous time variables. This calculates how much time has passed since the submission of the participant's first survey (6/19/25: for DVAL main study, we'll want to split this between part2 beeped and part6 beeped)
```{r}
unit = "mins"
interval_unit = 60

d_full <- d_full %>%
  group_by(participant_id) %>%
  # Find the time_complete value where obsno == 1 for each participant
  mutate(start_time = time_complete[obsno == 1][1]) %>%  # [1] in case of multiple obsno==1 (just take the first)
  ungroup() %>%
  # Calculate continuous time difference relative to that start_time
  mutate(continuoustime = as.numeric(difftime(time_complete, start_time, units = unit)))
```


#Check variable coherence: step skipped because coherence was observed in missingness analysis
#Dataframe format: step skipped because data formats were manipulated earlier in our preprocessing pathway
#Branching items 
#Participants' answer to the item, 'before_survey' determines which follow-up event rating variable gets sent subsequently: 'unpleasant', 'neutral', or 'pleasant'. 
#We want to ensure that participants' subsequent responses align with the structure of the survey. 
```{r}
d_full %>%
  mutate(pleasant_NA= !is.na(pleasant),
         unpleasant_NA= !is.na(unpleasant),
         neutral_NA= !is.na(neutral)) %>%  
  group_by(before_survey, pleasant_NA, unpleasant_NA, neutral_NA) %>%
  summarise(n())
```
# Interpretation of Branching step: it appears that the pattern of missingness aligns with the survey scheme. For example, 'It was generally neutral' is accompanied by non-missing data for the 'neutral' variable. This pattern exists for 'pleasant' and 'unpleasant' as well.

#Save new merged data (all EMA and baseline data).
```{r}
saveRDS(d_full, here("output", "EMA_and_baseline1.rds"))
```

#References
#Jones, A., Remmerswaal, D., Verveer, I., Robinson, E., Franken, I. H., Wen, C. K. F., & Field, M. (2019). Compliance with ecological momentary assessment protocols in substance users: A meta‐analysis. Addiction, 114(4), 609-619.

#Revol, J., Carlier, C., Lafit, G., Verhees, M., Sels, L., & Ceulemans, E. (2024). Preprocessing ESM data: a step-by-step framework, tutorial website, R package, and reporting templates.

