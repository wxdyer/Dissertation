---
title: "Data characteristics report"
author:
  - name: Walter G. Dyer, wdyer@psu.edu, Penn State University
date: "`r Sys.Date()`"
output: 
  html_document:
      toc: true
      number_sections: false
      toc_float: true
      toc_depth: 2
---


<!-- Javascript code to zoom in and out in the plots. -->
<!-- Code from Radovan Miletić: https://stackoverflow.com/questions/56361986/zoom-function-in-rmarkdown-html-plot -->
<script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
    $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
    $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
    $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
});
</script>

<!--------- INSTRUCTIONS ----------
This template would help you to structure and share the characteristic and the characteristics of your preprocessed dataset. 
It is based on the ESM preprocessing framework described in Revol and al. (under review). 
In addition, it is associated with an R packages, the esmtools package (package.esmtools.com), 
and a website to provide tutorials and R code for each step: preprocess.esmtools.com. 
Please, follow the instructions commented and add descriptions above each chunk you create. 
Note that the commented instructions are not displayed in the rendered document. 
<!--------------------------------->



<!-- This first chunk define the global settings and hidden variables of the file. -->
```{r, include=FALSE}
# For scroll bar when the output is longer than what is defined in the chunk:   {r, max.height='600px'}
options(width = 10000)
local({
  hook_output <- knitr::knit_hooks$get('output')
  knitr::knit_hooks$set(output = function(x, options) {
    if (!is.null(options$max.height)) options$attr.output <- c(
      options$attr.output,
      sprintf('style="max-height: %s;"', options$max.height)
    )
    hook_output(x, options)
  })
})

knitr::opts_chunk$set(message=FALSE, warning=FALSE) # set multiple global options here
```



This template follows the preprocessing framework described in Revol et. al. (2024) and can be found in the R package [esmtools](https://package.esmtools.com). 


# Import

Import packages
```{r}
# For data management:
library(dplyr)
library(tidyr)
library(readxl)
library(here)

# For data summary
library(skimr)

# For plots: 
library(ggplot2)
library(plotly) 
library(visdat) # viz missing values
library(naniar)
library(GGally)

# Manage date
library(lubridate)

# For codebook and participants book
library(DT)

# Tools
library(esmtools)
library(stringr)

```

# Read in data
```{r}
# Load the cleaned study_sample from the RDS file
study_sample <- readRDS(here("output", "cleaned_study_sample.RDS"))
```

<!-- 
Session info includes information such as R environment and package versions used, which ensures reproducibility.
Dataset info includes information that ensures traceability (e.g., date of modification, DOI, article associated) and reproducibility (e.g., checksum, size, dimensions) 
-->
Session info:
```{r}
sessionInfo()
```

Meta-info of the Preprocessed dataset:
```{r}
cat("## Path      : in-memory dataframe\n")
cat("## Extension : RDS (original format, now in-memory)\n")
cat("## Size      :", format(object.size(study_sample), units = "auto"), "\n\n")

# Dimensions
cat("## ncol      :", ncol(study_sample), "\n")
cat("## nrow      :", nrow(study_sample), "\n\n")

# Number of participants
id_var <- "participant_id"
n_participants <- n_distinct(study_sample[[id_var]])
cat("## Number of participants :", n_participants, "\n")

# Average number of observations per participant
avg_obs <- nrow(study_sample) / n_participants
cat("## Average number of observations per participant :", round(avg_obs, 1), "\n\n")

# Time period
time_var <- "init_time"
if(time_var %in% names(study_sample)) {
  time_min <- min(study_sample[[time_var]], na.rm = TRUE)
  time_max <- max(study_sample[[time_var]], na.rm = TRUE)
  cat("## Period : from", format(time_min, "%Y-%m-%d %H:%M:%S"),
      "to", format(time_max, "%Y-%m-%d %H:%M:%S"), "\n\n")
} else {
  cat("## Period : init_time variable not found in dataset\n\n")
}

# Variable names
cat("## Variables :", paste(names(study_sample), collapse = ", "), "\n")
```

# Codebook table (forthcoming)

In the table provided below, you will discover detailed information regarding each variable. 
This information has been compiled from a manually curated codebook, which offers textual explanations (e.g., Description). 
The remaining components (e.g., stats) have been generated by the function.

## First glimpse

The following chunk helps to have a first insight on what the dataset looks like.

```{r}
dim(study_sample)
```
```{r}
head(study_sample)
```

```{r}
tail(study_sample)
```
```{r}
glimpse(study_sample)
```
```{r}
summary(study_sample)
```
```{r}
table(study_sample$before_survey, useNA="ifany")
```

## Duplication
No issues detected.

**Look for duplicated rows:** the dataframe does not have duplicated rows.
```{r}
sum(duplicated(study_sample))
```

**Look for duplicated answers** (duplication in the self-reported items): no issue found regarding the number of self-reported items, the values of the variables involved, and the number of times duplicated .

```{r}
study_sample[!is.na(study_sample$init_time),] %>% # Select answered observations
    select(mood:pleasant) %>%  # Select self-report items
    group_by_all() %>%
    summarise(n = n()) %>% # Compute number of similar self-reported item values
    filter(n > 1) %>% arrange(desc(n)) %>% as.data.frame()
```


```{r}
# Check for duplicated answers based on key variables
answer_cols <- c("participant_id", "mood", "smoke", "before_survey", 
                 "unpleasant", "prior_mood", "smoked_since_last_survey", 
                 "pleasant", "session_id", "completion_time", "init_time")

dup_answers <- study_sample %>%
  group_by(across(all_of(answer_cols))) %>%
  filter(n() > 1) %>%
  ungroup()

cat("Duplicated answer sets:", nrow(dup_answers), "\n")
```

## Branching items

**Branching items are consistent:**

- when the participant chooses 'It was generally pleasant' for the variable 'before_survey', the variable  'pleasant' is displayed to the participant.
- when the participant chooses 'It was generally unpleasant' for the variable 'before_survey', the variable  'unpleasant' is displayed to the participant.
- n of observations for which both 'unpleasant' and 'pleasant' are missing (N=648) correspond to the n of observations for which participants reported 'It was generally neutral' (N=549; above) plus the n missinenss for the 'before_survey' variable (N=99; above), indicating no problems occurred at this step.

```{r}
# Count the number of observations for each before_survey category
branch_check <- study_sample %>%
  mutate(
    # Flag cases where both numeric branching variables are missing
    both_missing = is.na(pleasant) & is.na(unpleasant)
  ) %>%
  summarise(
    n_pleasant_displayed = sum(!is.na(pleasant) & before_survey == "It was generally pleasant"),
    n_unpleasant_displayed = sum(!is.na(unpleasant) & before_survey == "It was generally unpleasant"),
    n_neutral_branch = sum(both_missing & before_survey == "It was generally neutral"),
    n_both_missing_total = sum(both_missing),
    total_obs = n()
  )

branch_check
```
# Check variable coherence
# **Consistency of time-invariant variables.**
```{r}
study_sample %>%
  group_by(participant_id) %>%
  summarise(n_age_values = n_distinct(age)) %>%
  filter(n_age_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_race_values = n_distinct(race)) %>%
  filter(n_race_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_gender_values = n_distinct(gender)) %>%
  filter(n_gender_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_total_household_income_values = n_distinct(total_household_income)) %>%
  filter(n_total_household_income_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_panas_pos_values = n_distinct(panas_pos)) %>%
  filter(n_panas_pos_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_panas_neg_values = n_distinct(panas_neg)) %>%
  filter(n_panas_neg_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_bank_balance_values = n_distinct(bank_balance)) %>%
  filter(n_bank_balance_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_ftnd_sum_values = n_distinct(ftnd_sum)) %>%
  filter(n_ftnd_sum_values > 1)

study_sample %>%
  group_by(participant_id) %>%
  summarise(n_cigsperday_values = n_distinct(cigsperday)) %>%
  filter(n_cigsperday_values > 1)
```
No issues detected.

## Further analysis of missing values

Here, our goal is to further characterize the patterns of missing values and address any preliminary issues related to them.
The following plot gives an overview of the missing values in the dataframe.


#### Overview of missing values

```{r, fig.width=7, fig.height=7}
# Reorder variables
data = study_sample %>% arrange(participant_id, completion_time)

# Overiew of missing values
vis_miss(study_sample)
```
We can see multiple patterns and some missingness among the EMA variables.

# Skipped Revol & colleagues' (2024)step to check coherence of missing values in the variables of interest because what would go here -- the missingness pattern between 'before_survey', 'pleasant', and 'unpleasant' were already examined above. 

# Create time variables
```{r}
study_sample <- study_sample %>%
  
  arrange(participant_id, completion_time) %>%
  
  group_by(participant_id) %>%
  
  mutate(
    # Time components
    year   = year(completion_time),
    month  = month(completion_time),
    day    = day(completion_time),
    hour   = hour(completion_time),
    minute = minute(completion_time),
    
    # Observation number within participant
    obsno = row_number(),
    
    # Day number since first beep
    dayno = as.numeric(
      difftime(
        as.Date(completion_time),
        as.Date(min(completion_time, na.rm = TRUE)),
        units = "days"
      )
    ) + 1,
    
    # Study duration in days
    duration = as.numeric(
      difftime(
        as.Date(max(completion_time, na.rm = TRUE)),
        as.Date(min(completion_time, na.rm = TRUE)),
        units = "days"
      )
    ) + 1
  ) %>%
  
  ungroup() %>%
  
  # Beep number within day
  group_by(participant_id, dayno) %>%
  mutate(beepno = row_number()) %>%
  ungroup()

```

#Flag (in)valid observations

#Modification text: using logical tests, we define which observations are valid. The 'valid' observations are the ones where there are no missing values in the variables of interest (i.e., 'mood', 'before_survey', 'smoke'), and two others ('pleasant', 'unpleasant') in function of the branching items (see above). We created a function that can be used later.

```{r}
# Function to flag valid observations
check_validity <- function(df) {
  
  # Check core variables are not missing
  mood_ok          <- !is.na(df$mood)
  before_survey_ok <- !is.na(df$before_survey)
  smoke_ok         <- !is.na(df$smoke)
  
  # Branching variable condition: at least one of the branching variables is non-missing
  # For 'pleasant' or 'unpleasant' depending on what should have been displayed
  branch_ok <- ifelse(
    df$before_survey == "It was generally pleasant", !is.na(df$pleasant),
    ifelse(df$before_survey == "It was generally unpleasant", !is.na(df$unpleasant), TRUE)
  )
  
  # Combine all conditions
  is_valid <- mood_ok & before_survey_ok & smoke_ok & branch_ok
  
  # Convert to integer (1 = valid, 0 = invalid)
  as.integer(is_valid)
}

# Apply function to study_sample and create 'valid' column
study_sample$valid <- check_validity(study_sample)

# Quick check
table(study_sample$valid)
```

#Design and sample scheme checking

This section is dedicated to checking and solving issues due to inconsistencies between the planned and the actual design of the study.

## Calendar

Overview when the beeps were completed in a calendar format

```{r}
study_sample %>%
  filter(!is.na(completion_time)) %>%    
  mutate(
    year = year(completion_time),
    month = month(completion_time),
    day = day(completion_time)
  ) %>%
  group_by(year, month, day) %>%
  summarise(n_beeps = n(), .groups = "drop") %>%
  ggplot(aes(x = month, y = day, fill = n_beeps)) +
  geom_tile(color = "grey80") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  facet_wrap(~year, ncol = 2) +
  scale_y_reverse() +
  labs(
    title = "Calendar of Beeps Across 4 Years of Data Collection",
    x = "Month",
    y = "Day",
    fill = "N Beeps"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

## Sampling scheme plot and quantity of completed beeps
We proceed to the checking of the actual sample scheme and compare it to the defined one. 
```{r, warning=FALSE, message=FALSE}
study_sample %>%
  filter(!is.na(completion_time)) %>%
  mutate(
    weekday_type = ifelse(wday(completion_time, week_start = 1) %in% c(6,7), "weekend", "weekday")
  ) %>%
  group_by(participant_id, dayno, weekday_type) %>%
  summarise(n_beeps = n(), .groups = "drop") %>%
  ggplot(aes(x = factor(participant_id), y = factor(dayno))) +
  geom_point(aes(color = factor(n_beeps), shape = weekday_type), size = 1.5) +  # smaller points
  scale_color_brewer(palette = "Set2") +
  theme_minimal(base_size = 8) +  # smaller base text size
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 6),
    axis.text.y = element_text(size = 6),
    legend.text = element_text(size = 7),
    legend.title = element_text(size = 8)
  ) +
  labs(
    title = "Sampling scheme plot of completed EMA beeps",
    x = "Participant ID",
    y = "Cumulative Day",
    color = "Number of completed beeps",
    shape = "Day type"
  ) 
```

Here we can see that week(end) days are unevenly distributed across participants, that participants who skip a survey one day tend to skip a survey on another day, and that compliance is relatively high across participants. 

```{r}
# Examine number of completed beeps per participant
study_sample %>%
  group_by(participant_id) %>% 
  summarize(n_completed_beeps = n(), .groups = "drop") %>%
  ggplot(aes(x = factor(participant_id), y = n_completed_beeps)) +
    geom_col(position = "dodge", fill = "steelblue") +
    scale_y_continuous(breaks = seq(0, max(study_sample$obsno, na.rm = TRUE), 5)) +
    labs(
      title = "Number of completed beeps per participant",
      x = "Participant ID",
      y = "Completed beeps"
    ) +
    theme_minimal(base_size = 10) +  # smaller base font size
    theme(
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
      plot.title = element_text(face = "bold", size = 12)
    )
```
## Coherence timestamps

We check whether there is timestamp incoherence within observations (e.g., an observation with 'start' time after the 'end' time) or between observations (e.g., an observation that was scheduled after another one but with a 'start' time that is before).
```{r}
# Select and order relevant variables
df <- study_sample[, c("participant_id", "obsno",
                       "init_time", "completion_time")]

df <- df[order(df$participant_id, df$obsno), ]


# Timestamp coherence within observations

df %>%
  group_by(participant_id) %>%
  mutate(
    end_before_start = completion_time < init_time
  ) %>%
  filter(end_before_start) %>%
  ungroup() %>%
  as.data.frame()


# Timestamp coherence between observations

df %>%
  filter(!is.na(init_time), !is.na(completion_time)) %>%
  group_by(participant_id) %>%
  mutate(
    prev_completion = lag(completion_time),
    overlap_issue = prev_completion > init_time
  ) %>%
  filter(overlap_issue) %>%
  ungroup() %>%
  as.data.frame()

```
No issues detected.

#Participants' response behaviors

This section is dedicated to investigating how well participants engaged with the ESM study looking particularly for problematic patterns of behaviors (e.g., invalid observations, response time, careless responding).

## Sampling scheme, quantity of beeps and time started

We check how well participants followed the sampling scheme.

No issues detected.

```{r}
# Sampling Scheme plot: this plot illustrates the start times of participants’ valid observations. The x-axis represents the observation number and the y-axis shows the distribution across weekdays and weekends. We see that participant 238 only produces 10/18 valid observations and that occurrences of missing valid observations tend to exist toward the end of the observation period. 
study_sample %>%
  filter(valid == 1) %>%
  mutate(
    weekday = ifelse(
      wday(init_time, week_start = 1) %in% c(6, 7),
      "weekend",
      "weekday"
    )
  ) %>%
  ggplot(aes(x = obsno, y = factor(participant_id))) +
  geom_point(aes(color = weekday), size = 1) +
  labs(
    title = "Sampling scheme of the valid observations",
    y = "Participant id",
    x = "Observation number"
  )
```

```{r}
# Sampling scheme plot: this plot illustrates the start times of participants’ valid observations with continuous x-axis over the days of participation.

df <- study_sample %>%
  filter(valid == 1) %>%
  group_by(participant_id) %>%
  mutate(
    start_date = as.Date(min(init_time, na.rm = TRUE))
  ) %>%
  ungroup() %>%
  mutate(
    continuoustime = as.numeric(
      difftime(init_time, start_date, units = "mins")
    )
  )

# Number of study days
max_day <- ceiling(max(df$continuoustime, na.rm = TRUE) / 1440)

# Day boundaries (for vertical lines)
day_boundaries <- seq(0, max_day * 1440, by = 1440)

# Midpoints of each day (for centered labels)
day_midpoints <- day_boundaries[-length(day_boundaries)] + 720

# Labels
day_labels <- paste0(seq_len(length(day_midpoints)))

df %>%
  ggplot(aes(x = continuoustime, y = factor(participant_id))) +
  geom_point(size = 0.8) +
  scale_x_continuous(
    breaks = day_midpoints,
    labels = day_labels
  ) +
  geom_vline(xintercept = day_boundaries) +
  labs(
    title = "Continuous sampling scheme of the valid observations",
    y = "Participant_id",
    x = "Day number"
  )
```


```{r}
# Number of valid response over 'obsno' and it shows a slight decrease over time.
study_sample %>% 
  filter(valid==1) %>% 
  group_by(obsno) %>% summarize(n = n()) %>%
  ggplot(aes(x=obsno,y=n)) +
      geom_col(position = "dodge") +
        labs(title="Number of valid response over obsno",
             y="Number of valid beeps",x="Observation number")
```
```{r}
# Time of day beeps were started and (and valid).
study_sample %>%
  filter(valid == 1) %>%
  mutate(
    weekday = ifelse(
      wday(init_time, week_start = 1) %in% c(6, 7),
      "weekend",
      "weekday"
    ),
    time_of_day = hms::as_hms(init_time)
  ) %>%
  ggplot(aes(x = time_of_day)) +
  geom_histogram(bins = 100) +
  scale_x_time(breaks = scales::date_breaks("1 hour")) +
  facet_grid(weekday ~ .) +
  labs(
    title = "Time of day the beeps were started (and valid)",
    y = "Quantity of beeps started and valid",
    x = "Time of day"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Number of interactions
**Hour at which the beeps were started (in blue) and missed (in red):**
```{r}
df_interact <- study_sample %>%
  mutate(
    hour = hour(init_time),
    sent_ = !is.na(init_time),
    weekday = ifelse(wday(init_time, week_start = 1) %in% c(6, 7), "weekend", "weekday")
  ) %>%
  group_by(hour, weekday) %>%
  summarise(
    interact = sum(valid),
    open = sum(sent_)
  ) %>%
  mutate(not_interact = open - interact) %>%
  tidyr::pivot_longer(cols = c(interact, not_interact), names_to = "type", values_to = "value")

df_interact %>%
  mutate(type = factor(type, levels = c("not_interact", "interact"))) %>%
  ggplot(aes(x = factor(hour), y = value, fill = type)) +
  geom_col(position = "stack") +
  facet_grid(weekday ~ .) +
  labs(
    title = "Number of interactions and non-interactions with the questionnaire by hour",
    y = "Number of beeps",
    x = "Hour of day",
    fill = "Interaction"
  )
```
## Delays

Compute delay to fill  variables. Revol & colleagues' (2024) preprocessing steps for computing delay to fill is not possible because we lack a 'sent' variable. Will be only used for the creation of plot and won't be exported in the preprocessed dataframe. We see most of the valid surveys are submitted in under five minutes, which is expected. 
```{r}
study_sample <- study_sample %>%
  mutate(
    daily_end_min   = as.numeric(difftime(completion_time, init_time, units = "mins"))
  )

study_sample %>%
  filter(valid == 1 & !is.na(daily_end_min)) %>%
  ggplot(aes(x = daily_end_min)) +
    geom_histogram(bins = 100, fill = "steelblue", color = "black") +
    labs(
      title = "Histogram of questionnaire durations (valid beeps)",
      y = "Number of beeps",
      x = "Duration in minutes"
    )
```
#### Interval 2 beeps

No issues detected.
```{r}
# Compute time intervals between consecutive beeps within a day
study_sample_intervals <- study_sample %>%
  filter(valid == 1) %>% 
  arrange(participant_id, obsno) %>%
  group_by(participant_id, dayno) %>%
  mutate(time_int = as.numeric(difftime(lead(init_time), init_time, units = "mins"))) %>%
  ungroup()

# Plot histogram of intra-day beep intervals
study_sample_intervals %>%
  filter(!is.na(time_int)) %>%  # remove last beep in each day (no next beep)
  ggplot(aes(x = time_int)) +
    geom_histogram(bins = 100, fill = "steelblue", color = "black") +
    labs(
      title = "Histogram of delays between two subsequent beeps within a day",
      y = "Number of beeps",
      x = "Delay (minutes)"
    )
```

## Compliance Rate

We computed compliance rate scores for participants. We based this off the valid observation definition above and that each participant should have 18 valid observations.
```{r}
obsno_max = 18
study_sample$compliance = ave(study_sample$valid, study_sample$participant_id, FUN=function(x) sum(x, na.rm=TRUE)) / obsno_max

study_sample %>%
    group_by(participant_id) %>% slice(1) %>%    # Keep one row per participant
    ggplot(aes(y=compliance, x=factor(participant_id))) +
        geom_col(position = "dodge") +
        labs(title="Compliance score of each participant",
            y="Compliance",x="Participant id")
study_sample %>%
    group_by(participant_id) %>% slice(1) %>%    # Keep one row per participant
    ggplot(aes(x=compliance)) +
        geom_histogram() +
        labs(title="Histogram of the compliance score",
            y="Number of participant",x="Compliance")
```

# Study and data characteristics

Following, you will find a selection of plot and descriptive analysis that give insight into important aspects of how well the data follow the pre-defined sampling scheme and the study design, as well as whether participants engaged in problematic response behaviors (e.g., careless responding).

## Overview
This section provides information about the global characteristics of the dataset (e.g., patterns of the missing values).
<!-- 
This section correspond to Step 1 of the preprocess ESM framework. 
-->

<br>

**Participant time-invariant values:**
```{r}
unique(data[,c("participant_id","age","compliance")])
```


### Compliance






# Descriptive statistics and visualization

This section gives insight into the variables themselves (e.g., distribution, correlation plots).
In particular, a selection of relevant plots are displayed that help to investigate the within- and between-person differences (e.g., in time series, variable distributions), and patterns (e.g., variation of responses in function of a time variable).
Additionally, a sub-section contains a participant book providing specific data information about each participant.


**Overall distributions:** of 'mood' and 'smoke' variables.
```{r}
study_sample %>%
  select(mood, smoke) %>%
  pivot_longer(cols = everything(), names_to = "var", values_to = "value") %>%
  filter(is.finite(value)) %>%   # removes NA, NaN, Inf
  ggplot(aes(x = value)) +
    geom_histogram(aes(y = after_stat(density)), 
                   alpha = 0.7, bins = 50) + 
    geom_density(alpha = 0.5) +
    facet_grid(var ~ ., scales = "free")
```



```{r}
# mood & unpleasant
study_sample %>%
  ungroup() %>%
  select(mood, unpleasant) %>%
  filter(!is.na(mood) & !is.na(unpleasant)) %>%  # remove rows with missing values
  ggpairs(
    title = "Correlation: Mood and Unpleasant",
    upper = list(continuous = wrap("cor")),     # correlation coefficient in upper triangle
    diag  = list(continuous = wrap("densityDiag")), # density on diagonal
    lower = list(continuous = wrap("points"))   # scatterplots in lower triangle
  )
```

```{r}
# Mood & Pleasant
study_sample %>%
  ungroup() %>%
  select(mood, pleasant) %>%
  filter(!is.na(mood) & !is.na(pleasant)) %>%  # remove rows with missing values
  ggpairs(
    title = "Correlation: Mood and Pleasant",
    upper = list(continuous = wrap("cor")),       # correlation coefficient
    diag  = list(continuous = wrap("densityDiag")), # density on diagonal
    lower = list(continuous = wrap("points"))     # scatterplots
  )
```

```{r}
# Mood & Smoke
study_sample %>%
  ungroup() %>%
  select(mood, smoke) %>%
  filter(!is.na(mood) & !is.na(smoke)) %>%  # remove rows with missing values
  ggpairs(
    title = "Correlation: Mood and Smoke",
    upper = list(continuous = wrap("cor")),       # correlation coefficient
    diag  = list(continuous = wrap("densityDiag")), # density on diagonal
    lower = list(continuous = wrap("points"))     # scatterplots
  )
```

```{r}
# Smoke & Unpleasant
study_sample %>%
  ungroup() %>%
  select(smoke, unpleasant) %>%
  filter(!is.na(smoke) & !is.na(unpleasant)) %>%  # remove rows with missing values
  ggpairs(
    title = "Correlation: Smoke and Unpleasant",
    upper = list(continuous = wrap("cor")),         # correlation coefficient
    diag  = list(continuous = wrap("densityDiag")), # density on diagonal
    lower = list(continuous = wrap("points"))       # scatterplots
  )
```

```{r}
# Smoke & Pleasant
study_sample %>%
  ungroup() %>%
  select(smoke, pleasant) %>%
  filter(!is.na(smoke) & !is.na(pleasant)) %>%  # remove rows with missing values
  ggpairs(
    title = "Correlation: Smoke and Pleasant",
    upper = list(continuous = wrap("cor")),         # correlation coefficient
    diag  = list(continuous = wrap("densityDiag")), # density on diagonal
    lower = list(continuous = wrap("points"))       # scatterplots
  )
```


# Descriptive statistics and visualization
Statical models used later on are sensitive to the distribution of the variables. We therefore checked the distributions of the variable at a participant level.
```{r}
#Density plot of mood variable
study_sample %>%
  filter(!is.na(mood)) %>% 
    ggplot(aes(x=mood, color=factor(participant_id))) +  
        geom_density(alpha = 1) +
        theme(legend.position = "none") +
        labs(title="Density plot of the mood variable")
```
```{r}
#Density plot of smoke variable
study_sample %>%
  filter(!is.na(smoke)) %>% 
    ggplot(aes(x=smoke, color=factor(participant_id))) +  
        geom_density(alpha = 1) +
        theme(legend.position = "none") +
        labs(title="Density plot of the smoke variable")
```
